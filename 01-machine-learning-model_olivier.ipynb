{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "\n",
    "import shelter\n",
    "from shelter.config import data_dir\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this hackathon we'll try to predict the outcome of animals (adoption, etc.) at the Austin Animal Center using intake data (breed, age, etc.).\n",
    "We'll use the data from [this Kaggle competition](https://www.kaggle.com/c/shelter-animal-outcomes).\n",
    "At the end of the hackathon you should be able to send your own submission to Kaggle!\n",
    "\n",
    "To start, read the documentation on [Kaggle](https://www.kaggle.com/c/shelter-animal-outcomes) and download the [data](https://www.kaggle.com/c/shelter-animal-outcomes/data).\n",
    "Unzip the data in the folder `data/`.\n",
    "There should be (at least) three files: `sample_submission.csv`, `train.csv` and `test.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data with the functions from our own `shelter` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = \"C://projects//gdd//ml-production//data\"\n",
    "\n",
    "train = shelter.data.load_data(os.path.join(data_dir, 'train.csv'))\n",
    "test = shelter.data.load_data(os.path.join(data_dir, 'test.csv'))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = train['outcome_type'].value_counts().plot(kind='bar', rot=45)\n",
    "ax.set_ylabel('# animals')\n",
    "ax.set_title('Occurrence of outcome types')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that you've got the data, try to create a model that is able to predict the `outcome_type` given the intake data.\n",
    "Our final metric is the `f1-score` over all classes.\n",
    "\n",
    "> #### Tips\n",
    "> \n",
    "* First create a baseline model that randomly predicts a class given the class occurrences.\n",
    "* `sklearn` doesn't work with string values, you probably want to look at [`pd.get_dummies()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html), `sklearn`'s [`LabelEncoder`](http://scikit-learn.org/stable/modules/preprocessing_targets.html) or [`OneHotEncoder`](http://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features).\n",
    "* Try to a create model that predicts only one outcome type (e.g. `Adoption`) before focussing on all outcomes.\n",
    "* `sklearn` has many models for [supervised learning](http://scikit-learn.org/stable/supervised_learning.html), try to find one that fits the problem.\n",
    "* Look at [Kaggle Kernels](https://www.kaggle.com/c/shelter-animal-outcomes/kernels) for inspiration.\n",
    "* You will get better performance with some [feature engineering](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/).\n",
    "* Once you got your first model working, generate predictions for `test.csv` and submit it on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pepare train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train\n",
    "                                                    , train['outcome_type']\n",
    "                                                    , test_size=0.20 \n",
    "                                                    , random_state=42)\n",
    "        \n",
    "#X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "# Baseline Model: stratified dummy classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = pd.get_dummies(train[['animal_type', 'sex_upon_outcome', 'age_upon_outcome', 'breed', 'color']])\n",
    "X = [[0]]*len(X_train)\n",
    "y = y_train #['outcome_type'].tolist()\n",
    "\n",
    "prediction = DummyClassifier(strategy = \"stratified\", random_state=None, constant=None)\n",
    "prediction.fit(X,y)\n",
    "y_pred = prediction.predict([[0]]*len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F1 _score\n",
    "f1_score(y_test,y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model:\n",
    "### Using animal type as a single predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X_train[['animal_type']])\n",
    "y = y_train\n",
    "\n",
    "prediction = RandomForestClassifier()\n",
    "prediction.fit(X,y)\n",
    "y_pred = prediction.predict(pd.get_dummies(X_test[['animal_type']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F1 _score\n",
    "f1_score(y_test,y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model:\n",
    "### Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shelter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/Users/janellezoutkamp/Documents/practice/accelerator/ml-production/data\"\n",
    "\n",
    "train = shelter.data.load_data(os.path.join(data_dir, 'train.csv'))\n",
    "test = shelter.data.load_data(os.path.join(data_dir, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = shelter.data.add_features(train)\n",
    "score_df = shelter.data.add_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifying dogs into most frequent 10\n",
    "\n",
    "N_TOP = 20\n",
    " \n",
    "top_breeds = train_df['breed'].value_counts().index[:N_TOP]\n",
    "is_top = train_df['breed'].isin(top_breeds)\n",
    "\n",
    "# breeds = train_df.loc[is_top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['breed'].loc[~is_top] = 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with added features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_var = ['breed','is_dog', 'has_name', 'sex', 'neutered', 'hair_type', 'days_upon_outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df[pred_var]\n",
    "                                                    , train_df['outcome_type']\n",
    "                                                    , test_size=0.20 \n",
    "                                                    , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc = category_encoders.OneHotEncoder(cols = ['is_dog', 'has_name', 'sex', 'neutered', 'hair_type', 'breed']\n",
    "                                     ,handle_unknown = 'ignore').fit(X_train, y_train)\n",
    "\n",
    "X_train_numeric = enc.transform(X_train)\n",
    "\n",
    "reference_var = X_train_numeric.columns.str.endswith('_0')\n",
    "X_train_numeric = X_train_numeric.loc[:, ~reference_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_numeric = enc.transform(X_test)\n",
    "X_test_numeric.head()\n",
    "\n",
    "reference_var = X_test_numeric.columns.str.endswith('_0')\n",
    "X_test_numeric = X_test_numeric.loc[:, ~reference_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in X_train_numeric.columns:\n",
    "    print(\"The number of null values in:{} == {}\".format(_, X_train_numeric[_].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_numeric['days_upon_outcome'] = X_train_numeric['days_upon_outcome'].fillna(9999)\n",
    "X_test_numeric['days_upon_outcome'] = X_test_numeric['days_upon_outcome'].fillna(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\"randomforestclassifier__n_estimators\" : [10, 20, 30, 40],\n",
    "             \"randomforestclassifier__max_depth\" : [None, 6, 8, 10, 4],\n",
    "             \"randomforestclassifier__max_leaf_nodes\": [None, 5, 10, 20, 15], \n",
    "             \"randomforestclassifier__min_impurity_split\": [0.1, 0.2, 0.3, 0.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train_numeric, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set score: {:.2f}\".format(grid.score(X_test_numeric, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, grid.predict(X_test_numeric), average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE SUBMISSION\n",
    "\n",
    "test = shelter.data.load_data(os.path.join(data_dir, 'test.csv'))\n",
    "\n",
    "score_df = shelter.data.add_features(test)\n",
    "\n",
    "N_TOP = 20\n",
    "is_top = score_df['breed'].isin(top_breeds)\n",
    "score_df['breed'].loc[~is_top] = 'Other'\n",
    "\n",
    "pred_var = ['breed','is_dog', 'has_name', 'sex', 'neutered', 'hair_type', 'days_upon_outcome']\n",
    "score_df = score_df[pred_var]\n",
    "\n",
    "score_numeric = enc.transform(score_df)\n",
    "\n",
    "reference_var = score_numeric.columns.str.endswith('_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_numeric = score_numeric.loc[:, ~reference_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_numeric['days_upon_outcome'] = score_numeric['days_upon_outcome'].fillna(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = grid.predict_proba(score_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(prediction, columns=grid.classes_)\n",
    "submission['ID'] = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reordered = submission.loc[:, ['ID', 'Adoption', 'Died', 'Euthanasia', 'Return_to_owner', 'Transfer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reordered.to_csv('kaggle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_clean = train[['outcome_type', 'animal_type', 'sex_upon_outcome', 'age_upon_outcome', 'breed', 'color']]\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_clean['age_upon_outcome'].str.split('')\n",
    "train_clean['age'], train_clean['unit'] = train_clean.age_upon_outcome.str.split(' ', 1).str\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
